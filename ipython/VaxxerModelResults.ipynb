{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baking-buying",
   "metadata": {},
   "source": [
    "# Vaccine skepticism detection by network embedding\n",
    "\n",
    "In this work, we intended to develop techniques that are able to efficiently differentiate between pro-vaxxer and vax-skeptic Twitter content related to COVID19 vaccines. After multiple data preprocessing steps, we evaluated Tweet content and user interaction network classification by combining text classifiers with several node embedding and community detection\n",
    "models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0,\"../python\")\n",
    "from vaxxer.models import VaxxerClassifier\n",
    "from vaxxer.utils import show_dynamic_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-paste",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from plotly.offline import init_notebook_mode\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "# Make plotly work with Jupyter notebook\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-security",
   "metadata": {},
   "source": [
    "# 1. Download train-test data\n",
    "\n",
    "We provide a bash script (`download_data.sh`) to download our Twitter data set related to COVID19 vaccine skepticism.\n",
    "\n",
    "To comply data publication policy of Twitter, we cannot share the raw data. Instead, we publish our data in two different packages to provide reproducibility and encourage future work:\n",
    "\n",
    "- **[Twitter data identifiers]():** contains only tweet ID and user ID for each collected tweet. We further publish the underlying reply graph that we used to fit node embedding and community detection methods. \n",
    "\n",
    "- **[Tweet representations](http://info.ilab.sztaki.hu/~fberes/covid_vaccine_data/covid_vaxxer_representations_2021-09-24.zip):** In this package, we publish the data that we used for model training and evaluation. For tweet classification, we used the following three modalities with logistic regression:\n",
    "\n",
    "   * **1. text:** 1,000 dimensional TF-IDF vector of tweet text;\n",
    "   * **2. history:** Four basic statistics calculated from past tweet labels of the same user;\n",
    "   * **3. embedding:** 128-dimensional user representation in the reply network.\n",
    "\n",
    "In this notebook, we **only address tweet representations** that we load with `VaxxerClassifier` to analyze the global and dynamic performance for each modality in the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ..\n",
    "if [[ -d data ]]\n",
    "then\n",
    "    rm -r data\n",
    "fi\n",
    "bash scripts/download_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-links",
   "metadata": {},
   "source": [
    "# 2. Global model performance\n",
    "\n",
    "First, we load different combinations of modalities (e.g. text-only, text and network embedding etc.) to incorporate in our tweet classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"../data/covid_vaxxer_representations/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = VaxxerClassifier(\"tfidf\", \"Vax-skeptic\", drop_irrelevant=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-measurement",
   "metadata": {},
   "source": [
    "### Different modality settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"text\":(True, False, False),\n",
    "    \"text+history\":(True, True, False),\n",
    "    \"text+embedding\":(True, False, True),\n",
    "    \"text+embedding+history\":(True, True, True)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-renewal",
   "metadata": {},
   "source": [
    "### Experimental setting\n",
    "We split the tweet data in time to 70% training (2551 tweets) and 30% testing (1094 tweets). Then we calculate AUC for the whole test set.\n",
    "\n",
    "### Results\n",
    "\n",
    "- Not surprisingly, **user historical statistics** has strong contribution as users usually stick to their past opinion.\n",
    "   - 4.27\\% improvement compared to text-only model (AUC: 0.8385 -> 0.8743)\n",
    "-  **User representations from the Twitter reply network** improve performance even more\n",
    "   - 7.92\\% improvement compared to text-only model (AUC: 0.8385 -> 0.9024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for key, config in configs.items():\n",
    "    text, history, network = config\n",
    "    X_tr, X_te = classifier.load(model_dir, use_text=text, use_history=history, use_network=network)\n",
    "    clf, tr_pred, te_pred = classifier.fit_vaxxer_classifier(X_tr, X_te, {\"model\":\"newton-cg\"})\n",
    "    te_pred[\"experiment_id\"] = key\n",
    "    predictions.append(te_pred)\n",
    "    print(key, \"AUC:\", roc_auc_score(te_pred[\"label\"], te_pred[\"proba\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-russian",
   "metadata": {},
   "source": [
    "# 3. Dynamic model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "badrate = te_pred.groupby(\"date\")[\"label\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-affairs",
   "metadata": {},
   "source": [
    "Next, we show the changes in model performance over time as well as the vax-skeptic rate in the labeled data. \n",
    "\n",
    "By default, AUC is calculated for a 7 day long sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window = 7*86400\n",
    "fig = show_dynamic_auc(configs, predictions, badrate, time_window)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-illness",
   "metadata": {},
   "source": [
    "# 4. Node embedding visualization\n",
    "\n",
    "Finally, we visualize the pro-vaxxer and vax-skeptic user clusters that the best performing [Walklets](https://arxiv.org/abs/1605.02115) node embedding model managed to capture.\n",
    "\n",
    "For our experiments, we used the [karateclub](https://github.com/benedekrozemberczki/karateclub) open-source Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_embeddings(pred_df, X, show_hist=False):\n",
    "    mean_user_labels = pred_df.groupby(\"usr_id_str\")[\"label\"].mean()\n",
    "    if show_hist:\n",
    "        mean_user_labels.hist()\n",
    "    label_map = dict(mean_user_labels)\n",
    "    pred_tmp_df = pred_df.copy()\n",
    "    pred_tmp_df[\"label\"] = pred_tmp_df[\"usr_id_str\"].apply(lambda x: round(label_map[x]))\n",
    "    visu_df = pd.concat([pd.DataFrame(X[:,vax_skeptic_columns], index=pred_tmp_df.index), pred_tmp_df[[\"usr_id_str\",\"label\"]]], axis=1)\n",
    "    visu_df = visu_df.drop_duplicates(subset=\"usr_id_str\")\n",
    "    print(visu_df.shape)\n",
    "    return visu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-kingston",
   "metadata": {},
   "source": [
    "#### Load only node representations from the underlying Twitter reply network (128-dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_ne, X_te_ne = classifier.load(model_dir, use_text=False, use_history=False, use_network=True)\n",
    "clf_ne, tr_pred_ne, te_pred_ne = classifier.fit_vaxxer_classifier(X_tr_ne, X_te_ne, {\"model\":\"newton-cg\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-study",
   "metadata": {},
   "source": [
    "## Vax-skeptic users in the embedded space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-bahrain",
   "metadata": {},
   "source": [
    "#### Extract the most relevant coefficients of the LogisticRegression classifier that we fitted for this task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "vax_skeptic_coeffs = clf_ne.coef_\n",
    "vax_skeptic_coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_args = np.argsort(np.max(vax_skeptic_coeffs, axis=0))\n",
    "vax_skeptic_columns = [sorted_args[0],sorted_args[-1],sorted_args[-2]]\n",
    "print(vax_skeptic_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-valley",
   "metadata": {},
   "source": [
    "### a.) Kernel density estimation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_visu_df = show_embeddings(te_pred_ne, X_te_ne)\n",
    "g = sns.jointplot(\n",
    "    data=te_visu_df,\n",
    "    x=1, y=2, hue=\"label\",\n",
    "    kind=\"kde\",\n",
    "    legend=False\n",
    ")\n",
    "g.ax_joint.set_xlabel(\"\")\n",
    "g.ax_joint.set_ylabel(\"\")\n",
    "plt.legend(title='Vaccine view', loc='upper left', labels=['Skeptic', 'Pro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-associate",
   "metadata": {},
   "source": [
    "### b.) Scatterplot for short time intervals\n",
    "\n",
    "In the visualization, each point represents a user that was active in the selected time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = te_pred_ne.reset_index(drop=True)\n",
    "intervals = [\n",
    "    #(\"2021-04-27\",\"2021-05-03\"),\n",
    "    (\"2021-05-05\",\"2021-05-13\"),\n",
    "    #(\"2021-05-16\",\"2021-05-22\"),\n",
    "    #(\"2021-05-29\",\"2021-06-09\"),\n",
    "    #(\"2021-06-16\",\"2021-06-22\"),\n",
    "    #(\"2021-07-17\",\"2021-07-29\")\n",
    "]\n",
    "for from_date, to_date in intervals:\n",
    "    interval_df = meta_df[(meta_df[\"date\"]>=from_date) & (meta_df[\"date\"]<=to_date)]\n",
    "    interval_X = X_te_ne[interval_df.index,:]\n",
    "    print(len(interval_df), interval_X.shape)\n",
    "    interval_visu_df = show_embeddings(interval_df, interval_X)\n",
    "    g=sns.jointplot(\n",
    "        data=interval_visu_df,\n",
    "        x=1, y=2, hue=\"label\",\n",
    "        legend=False,\n",
    "    )\n",
    "    g.ax_marg_x.set_xlim(-3, 2)\n",
    "    g.ax_marg_y.set_ylim(-4, 3)\n",
    "    g.ax_joint.set_xlabel(\"\")\n",
    "    g.ax_joint.set_ylabel(\"\")\n",
    "    plt.legend(title='Vaccine view', loc='upper left', labels=['Skeptic', 'Pro'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
